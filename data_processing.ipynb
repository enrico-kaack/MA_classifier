{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from input.data_downloader import DataDownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root:Read from input/repos.txt\nINFO:root:Downloading 7 repositories...\n  0%|          | 0/7 [00:00<?, ?it/s]ERROR:root:Target path raw_data/scikit-learn/scikit-learn/master already exists\n 14%|█▍        | 1/7 [00:02<00:16,  2.73s/it]ERROR:root:Target path raw_data/pytorch/pytorch/master already exists\n 29%|██▊       | 2/7 [00:04<00:12,  2.54s/it]ERROR:root:Target path raw_data/ansible/ansible/devel already exists\n 43%|████▎     | 3/7 [00:06<00:09,  2.38s/it]ERROR:root:Target path raw_data/django/django/master already exists\n 57%|█████▋    | 4/7 [00:09<00:07,  2.42s/it]ERROR:root:Target path raw_data/pallets/flask/master already exists\n 71%|███████▏  | 5/7 [00:10<00:03,  1.99s/it]ERROR:root:Target path raw_data/keras-team/keras/master already exists\n 86%|████████▌ | 6/7 [00:11<00:01,  1.65s/it]ERROR:root:Target path raw_data/jakubroztocil/httpie/master already exists\n100%|██████████| 7/7 [00:12<00:00,  1.77s/it]\nINFO:root:Removing non-python files\nINFO:root:Total number of python files: 6623\n"
    }
   ],
   "source": [
    "downloader = DataDownloader(\"raw_data\")\n",
    "downloader.download_repos_in_file(\"input/repos.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read from source files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from input.data_read_write import DataReaderAndWriter\n",
    "data_handler = DataReaderAndWriter()\n",
    "data_handler.load_source_file_from(\"raw_data\")\n",
    "data_handler.dump_to_file(\"input/processed.pkl\")\n",
    "data = data_handler.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "1%|          | 44/6623 [00:00<00:17, 381.06it/s]\n 14%|█▍        | 952/6623 [00:17<04:40, 20.20it/s]WARNING:root:Syntax error on file:raw_data/ansible/ansible/devel/ansible-devel/test/support/windows-integration/collections/ansible_collections/ansible/windows/plugins/action/win_copy.py. Ignoring file\nWARNING:root:Syntax error on file:raw_data/ansible/ansible/devel/ansible-devel/test/support/windows-integration/collections/ansible_collections/ansible/windows/plugins/modules/win_stat.py. Ignoring file\nWARNING:root:Syntax error on file:raw_data/ansible/ansible/devel/ansible-devel/test/support/windows-integration/collections/ansible_collections/ansible/windows/plugins/modules/win_shell.py. Ignoring file\nWARNING:root:Syntax error on file:raw_data/ansible/ansible/devel/ansible-devel/test/support/windows-integration/collections/ansible_collections/ansible/windows/plugins/modules/win_file.py. Ignoring file\nWARNING:root:Syntax error on file:raw_data/ansible/ansible/devel/ansible-devel/test/support/windows-integration/collections/ansible_collections/ansible/windows/plugins/modules/win_ping.py. Ignoring file\nWARNING:root:Syntax error on file:raw_data/ansible/ansible/devel/ansible-devel/test/support/windows-integration/collections/ansible_collections/ansible/windows/plugins/modules/win_copy.py. Ignoring file\nWARNING:root:Syntax error on file:raw_data/ansible/ansible/devel/ansible-devel/test/support/windows-integration/collections/ansible_collections/ansible/windows/plugins/modules/win_acl.py. Ignoring file\n 21%|██        | 1359/6623 [00:26<03:01, 28.96it/s]WARNING:root:Syntax error on file:raw_data/ansible/ansible/devel/ansible-devel/lib/ansible/module_utils/ansible_release.py. Ignoring file\n 26%|██▌       | 1721/6623 [00:35<02:34, 31.68it/s]WARNING:root:Syntax error on file:raw_data/pytorch/pytorch/master/pytorch-master/tools/autograd/templates/annotated_fn_args.py. Ignoring file\n 45%|████▍     | 2962/6623 [01:38<01:44, 35.16it/s]WARNING:root:Syntax error on file:raw_data/pytorch/pytorch/master/pytorch-master/docs/caffe2/process.py. Ignoring file\n100%|██████████| 6623/6623 [03:01<00:00, 36.48it/s]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "extmanager\\ndef named_temporary_file(args, prefix, suffix, directory, content):\\n    \"\"\"\\n    :param args: CommonConfig\\n    :param prefix: str\\n    :param suffix: str\\n    :param directory: str\\n    :param content: str | bytes | unicode\\n    :rtype: str\\n    \"\"\"\\n    if args.explain:\\n        yield os.path.join(directory, \\'%stemp%s\\' % (prefix, suffix))\\n    else:\\n        with tempfile.NamedTemporaryFile(prefix=prefix, suffix=suffix, dir=directory) as tempfile_fd:\\n            tempfile_fd.write(to_bytes(content))\\n            tempfile_fd.flush()\\n\\n            yield tempfile_fd.name\\n\\n\\ndef write_json_test_results(category,  # type: ResultType\\n                            name,  # type: str\\n                            content,  # type: t.Union[t.List[t.Any], t.Dict[str, t.Any]]\\n                            formatted=True,  # type: bool\\n                            encoder=None,  # type: t.Optional[t.Callable[[t.Any], t.Any]]\\n                            ):  # type: (...) -> None\\n    \"\"\"Write the given json content to the specified test results path, creating directories as needed.\"\"\"\\n    path = os.path.join(category.path, name)\\n    write_json_file(path, content, create_directories=True, formatted=formatted, encoder=encoder)\\n\\n\\ndef write_text_test_results(category, name, content):  # type: (ResultType, str, str) -> None\\n    \"\"\"Write the given text content to the specified test results path, creating directories as needed.\"\"\"\\n    path = os.path.join(category.path, name)\\n    write_text_file(path, content, create_directories=True)\\n\\n\\ndef get_python_path(args, interpreter):\\n    \"\"\"\\n    :type args: TestConfig\\n    :type interpreter: str\\n    :rtype: str\\n    \"\"\"\\n    python_path = PYTHON_PATHS.get(interpreter)\\n\\n    if python_path:\\n        return python_path\\n\\n    prefix = \\'python-\\'\\n    suffix = \\'-ansible\\'\\n\\n    root_temp_dir = \\'/tmp\\'\\n\\n    if args.explain:\\n        return os.path.join(root_temp_dir, \\'\\'.join((prefix, \\'temp\\', suffix)))\\n\\n    python_path = tempfile.mkdtemp(prefix=prefix, suffix=suffix, dir=root_temp_dir)\\n    injected_interpreter = os.path.join(python_path, \\'python\\')\\n\\n    # A symlink is faster than the execv wrapper, but isn\\'t compatible with virtual environments.\\n    # Attempt to detect when it is safe to use a symlink by checking the real path of the interpreter.\\n    use_symlink = os.path.dirname(os.path.realpath(interpreter)) == os.path.dirname(interpreter)\\n\\n    if use_symlink:\\n        display.info(\\'Injecting \"%s\" as a symlink to the \"%s\" interpreter.\\' % (injected_interpreter, interpreter), verbosity=1)\\n\\n        os.symlink(interpreter, injected_interpreter)\\n    else:\\n        display.info(\\'Injecting \"%s\" as a execv wrapper for the \"%s\" interpreter.\\' % (injected_interpreter, interpreter), verbosity=1)\\n\\n        create_interpreter_wrapper(interpreter, injected_interpreter)\\n\\n    os.chmod(python_path, MODE_DIRECTORY)\\n\\n    if not PYTHON_PATHS:\\n        atexit.register(cleanup_python_paths)\\n\\n    PYTHON_PATHS[interpreter] = python_path\\n\\n    return python_path\\n\\n\\ndef create_temp_dir(prefix=None, suffix=None, base_dir=None):  # type: (t.Optional[str], t.Optional[str], t.Optional[str]) -> str\\n    \"\"\"Create a temporary directory that persists until the current process exits.\"\"\"\\n    temp_path = tempfile.mkdtemp(prefix=prefix or \\'tmp\\', suffix=suffix or \\'\\', dir=base_dir)\\n    atexit.register(remove_tree, temp_path)\\n    return temp_path\\n\\n\\ndef create_interpreter_wrapper(interpreter, injected_interpreter):  # type: (str, str) -> None\\n    \"\"\"Create a wrapper for the given Python interpreter at the specified path.\"\"\"\\n    # sys.executable is used for the shebang to guarantee it is a binary instead of a script\\n    # injected_interpreter could be a script from the system or our own wrapper created for the --venv option\\n    shebang_interpreter = sys.executable\\n\\n    code = textwrap.dedent(\\'\\'\\'\\n    #!%s\\n\\n    from __future__ import absolute_import\\n\\n    from os import execv\\n    from sys import argv\\n\\n    python = \\'%s\\'\\n\\n    execv(python, [python] + argv[1:])\\n    \\'\\'\\' % (shebang_interpreter, interpreter)).lstrip()\\n\\n    write_text_file(injected_interpreter, code)\\n\\n    os.chmod(injected_interpreter, MODE_FILE_EXECUTE)\\n\\n\\ndef cleanup_python_paths():\\n    \"\"\"Clean up all temporary python directories.\"\"\"\\n    for path in sorted(PYTHON_PATHS.values()):\\n        display.info(\\'Cleaning up temporary python directory: %s\\' % path, verbosity=2)\\n        shutil.rmtree(path)\\n\\n\\ndef get_coverage_environment(args, target_name, version, temp_path, module_coverage, remote_temp_path=None):\\n    \"\"\"\\n    :type args: TestConfig\\n    :type target_name: str\\n    :type version: str\\n    :type temp_path: str\\n    :type module_coverage: bool\\n    :type remote_temp_path: str | None\\n    :rtype: dict[str, str]\\n    \"\"\"\\n    if temp_path:\\n        # integration tests (both localhost and the optional testhost)\\n        # config and results are in a temporary directory\\n        coverage_config_base_path = temp_path\\n        coverage_output_base_path = temp_path\\n    elif args.coverage_config_base_path:\\n        # unit tests, sanity tests and other special cases (localhost only)\\n        # config is in a temporary directory\\n        # results are in the source tree\\n        coverage_config_base_path = args.coverage_config_base_path\\n        coverage_output_base_path = os.path.join(data_context().content.root, data_context().content.results_path)\\n    else:\\n        raise Exception(\\'No temp path and no coverage config base path. Check for missing coverage_context usage.\\')\\n\\n    config_file = os.path.join(coverage_config_base_path, COVERAGE_CONFIG_NAME)\\n    coverage_file = os.path.join(coverage_output_base_path, ResultType.COVERAGE.name, \\'%s=%s=%s=%s=coverage\\' % (\\n        args.command, target_name, args.coverage_label or \\'local-%s\\' % version, \\'python-%s\\' % version))\\n\\n    if not args.explain and not os.path.exists(config_file):\\n        raise Exception(\\'Missing coverage config file: %s\\' % config_file)\\n\\n    if args.coverage_check:\\n        # cause the \\'coverage\\' module to be found, but not imported or enabled\\n        coverage_file = \\'\\'\\n\\n    # Enable code coverage collection on local Python programs (this does not include Ansible modules).\\n    # Used by the injectors to support code coverage.\\n    # Used by the pytest unit test plugin to support code coverage.\\n    # The COVERAGE_FILE variable is also used directly by the \\'coverage\\' module.\\n    env = dict(\\n        COVERAGE_CONF=config_file,\\n        COVERAGE_FILE=coverage_file,\\n    )\\n\\n    if module_coverage:\\n        # Enable code coverage collection on Ansible modules (both local and remote).\\n        # Used by the AnsiballZ wrapper generator in lib/ansible/executor/module_common.py to support code coverage.\\n        env.update(dict(\\n            _ANSIBLE_COVERAGE_CONFIG=config_file,\\n            _ANSIBLE_COVERAGE_OUTPUT=coverage_file,\\n        ))\\n\\n        if remote_temp_path:\\n            # Include the command, target and label so the remote host can create a filename with that info. The remote\\n            # is responsible for adding \\'={language version}=coverage.{hostname}.{pid}.{id}\\'\\n            env[\\'_ANSIBLE_COVERAGE_REMOTE_OUTPUT\\'] = os.path.join(remote_temp_path, \\'%s=%s=%s\\' % (\\n                args.command, target_name, args.coverage_label or \\'remote\\'))\\n            env[\\'_ANSIBLE_COVERAGE_REMOTE_PATH_FILTER\\'] = os.path.join(data_context().content.root, \\'*\\')\\n\\n    return env\\n\\n\\ndef intercept_command(args, cmd, target_name, env, capture=False, data=None, cwd=None, python_version=None, temp_path=None, module_coverage=True,\\n                      virtualenv=None, disable_coverage=False, remote_temp_path=None):\\n    \"\"\"\\n    :type args: TestConfig\\n    :type cmd: collections.Iterable[str]\\n    :type target_name: str\\n    :type env: dict[str, str]\\n    :type capture: bool\\n    :type data: str | None\\n    :type cwd: str | None\\n    :type python_version: str | None\\n    :type temp_path: str | None\\n    :type module_coverage: bool\\n    :type virtualenv: str | None\\n    :type disable_coverage: bool\\n    :type remote_temp_path: str | None\\n    :rtype: str | None, str | None\\n    \"\"\"\\n    if not env:\\n        env = common_environment()\\n    else:\\n        env = env.copy()\\n\\n    cmd = list(cmd)\\n    version = python_version or args.python_version\\n    interpreter = virtualenv or find_python(version)\\n    inject_path = os.path.join(ANSIBLE_TEST_DATA_ROOT, \\'injector\\')\\n\\n    if not virtualenv:\\n        # injection of python into the path is required when not activating a virtualenv\\n        # otherwise scripts may find the wrong interpreter or possibly no interpreter\\n        python_path = get_python_path(args, interpreter)\\n        inject_path = python_path + os.path.pathsep + inject_path\\n\\n    env[\\'PATH\\'] = inject_path + os.path.pathsep + env[\\'PATH\\']\\n    env[\\'ANSIBLE_TEST_PYTHON_VERSION\\'] = version\\n    env[\\'ANSIBLE_TEST_PYTHON_INTERPRETER\\'] = interpreter\\n\\n    if args.coverage and not disable_coverage:\\n        # add the necessary environment variables to enable code coverage collection\\n        env.update(get_coverage_environment(args, target_name, version, temp_path, module_coverage,\\n                                            remote_temp_path=remote_temp_path))\\n\\n    return run_command(args, cmd, capture=capture, env=env, data=data, cwd=cwd)\\n\\n\\ndef resolve_csharp_ps_util(import_name, path):\\n    \"\"\"\\n    :type import_name: str\\n    :type path: str\\n    \"\"\"\\n    if data_context().content.is_ansible or not import_name.startswith(\\'.\\'):\\n        # We don\\'t support relative paths for builtin utils, there\\'s no point.\\n        return import_name\\n\\n    packages = import_name.split(\\'.\\')\\n    module_packages = path.split(os.path.sep)\\n\\n    for package in packages:\\n        if not module_packages or package:\\n            break\\n        del module_packages[-1]\\n\\n    return \\'ansible_collections.%s%s\\' % (data_context().content.prefix,\\n                                         \\'.\\'.join(module_packages + [p for p in packages if p]))\\n\\n\\ndef run_command(args, cmd, capture=False, env=None, data=None, cwd=None, always=False, stdin=None, stdout=None,\\n                cmd_verbosity=1, str_errors=\\'strict\\'):\\n    \"\"\"\\n    :type args: CommonConfig\\n    :type cmd: collections.Iterable[str]\\n    :type capture: bool\\n    :type env: dict[str, str] | None\\n    :type data: str | None\\n    :type cwd: str | None\\n    :type always: bool\\n    :type stdin: file | None\\n    :type stdout: file | None\\n    :type cmd_verbosity: int\\n    :type str_errors: str\\n    :rtype: str | None, str | None\\n    \"\"\"\\n    explain = args.explain and not always\\n    return raw_command(cmd, capture=capture, env=env, data=data, cwd=cwd, explain=explain, stdin=stdin, stdout=stdout,\\n                       cmd_verbosity=cmd_verbosity, str_errors=str_errors)\\n',\n  'problems': [{'type': 'RETURN_NULL', ' line_number': 170, 'col_offset': 8}]},\n {'file_path': 'raw_data/ansible/ansible/devel/ansible-devel/test/lib/ansible_test/_internal/constants.py',\n  'src': '\"\"\"Constants used by ansible-test. Imports should not be used in this file.\"\"\"\\nfrom __future__ import (absolute_import, division, print_function)\\n__metaclass__ = type\\n\\n# Setting a low soft RLIMIT_NOFILE value will improve the performance of subprocess.Popen on Python 2.x when close_fds=True.\\n# This will affect all Python subprocesses. It will also affect the current Python process if set before subprocess is imported for the first time.\\nSOFT_RLIMIT_NOFILE = 1024\\n\\n# File used to track the ansible-test test execution timeout.\\nTIMEOUT_PATH = \\'.ansible-test-timeout.json\\'\\n',\n  'problems': []},\n {'file_path': 'raw_data/ansible/ansible/devel/ansible-devel/test/lib/ansible_test/_internal/io.py',\n  'src': '\"\"\"Functions for disk IO.\"\"\"\\nfrom __future__ import (absolute_import, division, print_function)\\n__metaclass__ = type\\n\\nimport errno\\nimport io\\nimport json\\nimport os\\n\\nfrom . import types as t\\n\\nfrom .encoding import (\\n    ENCODING,\\n    to_bytes,\\n    to_text,\\n)\\n\\n\\ndef read_json_file(path):  # type: (t.AnyStr) -> t.Any\\n    \"\"\"Parse and return the json content from the specified path.\"\"\"\\n    return json.loads(read_text_file(path))\\n\\n\\ndef read_text_file(path):  # type: (t.AnyStr) -> t.Text\\n    \"\"\"Return the contents of the specified path as text.\"\"\"\\n    return to_text(read_binary_file(path))\\n\\n\\ndef read_binary_file(path):  # type: (t.AnyStr) -> bytes\\n    \"\"\"Return the contents of the specified path as bytes.\"\"\"\\n    with open_binary_file(path) as file:\\n        return file.read()\\n\\n\\ndef make_dirs(path):  # type: (str) -> None\\n    \"\"\"Create a directory at path, including any necessary parent directories.\"\"\"\\n    try:\\n        os.makedirs(to_bytes(path))\\n    except OSError as ex:\\n        if ex.errno != errno.EEXIST:\\n            raise\\n\\n\\ndef write_json_file(path,  # type: str\\n                    content,  # type: t.Union[t.List[t.Any], t.Dict[str, t.Any]]\\n                    create_directories=False,  # type: bool\\n                    formatted=True,  # type: bool\\n                    encoder=None,  # type: t.Optional[t.Callable[[t.Any], t.Any]]\\n                    ):  # type: (...) -> None\\n    \"\"\"Write the given json content to the specified path, optionally creating missing directories.\"\"\"\\n    text_content = json.dumps(content,\\n                              sort_keys=formatted,\\n                              indent=4 if formatted else None,\\n                              separators=(\\', \\', \\': \\') if formatted else (\\',\\', \\':\\'),\\n                              cls=encoder,\\n                              ) + \\'\\\\n\\'\\n\\n    write_text_file(path, text_content, create_directories=create_directories)\\n\\n\\ndef write_text_file(path, content, create_directories=False):  # type: (str, str, bool) -> None\\n    \"\"\"Write the given text content to the specified path, optionally creating missing directories.\"\"\"\\n    if create_directories:\\n        make_dirs(os.path.dirname(path))\\n\\n    with open_binary_file(path, \\'wb\\') as file:\\n        file.write(to_bytes(content))\\n\\n\\ndef open_text_file(path, mode=\\'r\\'):  # type: (str, str) -> t.TextIO\\n    \"\"\"Open the given path for text access.\"\"\"\\n    if \\'b\\' in mode:\\n        raise Exception(\\'mode cannot include \"b\" for text files: %s\\' % mode)\\n\\n    # noinspection PyTypeChecker\\n    return io.open(to_bytes(path), mode, encoding=ENCODING)\\n\\n\\ndef open_binary_file(path, mode=\\'rb\\'):  # type: (str, str) -> t.BinaryIO\\n    \"\"\"Open the given path for binary access.\"\"\"\\n    if \\'b\\' not in mode:\\n        raise Exception(\\'mode must include \"b\" for binary files: %s\\' % mode)\\n\\n    # noinspection PyTypeChecker\\n    return io.open(to_bytes(path), mode)\\n\\n\\nclass SortedSetEncoder(json.JSONEncoder):\\n    \"\"\"Encode sets as sorted lists.\"\"\"\\n    def default(self, obj):  # pylint: disable=method-hidden, arguments-differ\\n        if isinstance(obj, set):\\n            return sorted(obj)\\n\\n        return super(SortedSetEncoder).default(self, obj)\\n',\n  'problems': []},\n {'file_path': 'raw_data/ansible/ansible/devel/ansible-devel/test/lib/ansible_test/_internal/cache.py',\n  'src': '\"\"\"Cache for commonly shared data that is intended to be immutable.\"\"\"\\nfrom __future__ import (absolute_import, division, print_function)\\n__metaclass__ = type\\n\\n\\nclass CommonCache:\\n    \"\"\"Common cache.\"\"\"\\n    def __init__(self, args):\\n        \"\"\"\\n        :param args: CommonConfig\\n        \"\"\"\\n        self.args = args\\n\\n    def get(self, key, factory):\\n        \"\"\"\\n        :param key: str\\n        :param factory: () -> any\\n        :rtype: any\\n        \"\"\"\\n        if key not in self.args.cache:\\n            self.args.cache[key] = factory()\\n\\n        return self.args.cache[key]\\n\\n    def get_with_args(self, key, factory):\\n        \"\"\"\\n        :param key: str\\n        :param factory: (CommonConfig) -> any\\n        :rtype: any\\n        \"\"\"\\n\\n        if key not in self.args.cache:\\n            self.args.cache[key] = factory(self.args)\\n\\n        return self.args.cache[key]\\n',\n  'problems': []},\n {'file_path': 'raw_data/ansible/ansible/devel/ansible-devel/test/lib/ansible_test/_internal/__init__.py',\n  'src': '\"\"\"Support code for Ansible testing infrastructure.\"\"\"\\nfrom __future__ import (absolute_import, division, print_function)\\n__metaclass__ = type\\n',\n  'problems': []},\n {'file_path': 'raw_data/ansible/ansible/devel/ansible-devel/test/lib/ansible_test/_internal/powershell_import_analysis.py',\n  'src': '\"\"\"Analyze powershell import statements.\"\"\"\\nfrom __future__ import (absolute_import, division, print_function)\\n__metaclass__ = type\\n\\nimport os\\nimport re\\n\\nfrom .io import (\\n    read_text_file,\\n)\\n\\nfrom .util import (\\n    display,\\n)\\n\\nfrom .util_common import (\\n    resolve_csharp_ps_util,\\n)\\n\\nfrom .data import (\\n    data_context,\\n)\\n\\n\\ndef get_powershell_module_utils_imports(powershell_targets):\\n    \"\"\"Return a dictionary of module_utils names mapped to sets of powershell file paths.\\n    :type powershell_targets: list[TestTarget]\\n    :rtype: dict[str, set[str]]\\n    \"\"\"\\n\\n    module_utils = enumerate_module_utils()\\n\\n    imports_by_target_path = {}\\n\\n    for target in powershell_targets:\\n        imports_by_target_path[target.path] = extract_powershell_module_utils_imports(target.path, module_utils)\\n\\n    imports = dict([(module_util, set()) for module_util in module_utils])\\n\\n    for target_path in imports_by_target_path:\\n        for module_util in imports_by_target_path[target_path]:\\n            imports[module_util].add(target_path)\\n\\n    for module_util in sorted(imports):\\n        if not imports[module_util]:\\n            display.warning(\\'No imports found which use the \"%s\" module_util.\\' % module_util)\\n\\n    return imports\\n\\n\\ndef get_powershell_module_utils_name(path):  # type: (str) -> str\\n    \"\"\"Return a namespace and name from the given module_utils path.\"\"\"\\n    base_path = data_context().content.module_utils_powershell_path\\n\\n    if data_context().content.collection:\\n        prefix = \\'ansible_collections.\\' + data_context().content.collection.prefix + \\'plugins.module_utils.\\'\\n    else:\\n        prefix = \\'\\'\\n\\n    name = prefix + os.path.splitext(os.path.relpath(path, base_path))[0].replace(os.path.sep, \\'.\\')\\n\\n    return name\\n\\n\\ndef enumerate_module_utils():\\n    \"\"\"Return a list of available module_utils imports.\\n    :rtype: set[str]\\n    \"\"\"\\n    return set(get_powershell_module_utils_name(p)\\n               for p in data_context().content.walk_files(data_context().content.module_utils_powershell_path)\\n               if os.path.splitext(p)[1] == \\'.psm1\\')\\n\\n\\ndef extract_powershell_module_utils_imports(path, module_utils):\\n    \"\"\"Return a list of module_utils imports found in the specified source file.\\n    :type path: str\\n    :type module_utils: set[str]\\n    :rtype: set[str]\\n    \"\"\"\\n    imports = set()\\n\\n    code = read_text_file(path)\\n\\n    if data_context().content.is_ansible and \\'# POWERSHELL_COMMON\\' in code:\\n        imports.add(\\'Ansible.ModuleUtils.Legacy\\')\\n\\n    lines = code.splitlines()\\n    line_number = 0\\n\\n    for line in lines:\\n        line_number += 1\\n        match = re.search(r\\'(?i)^#\\\\s*(?:requires\\\\s+-module(?:s?)|ansiblerequires\\\\s+-powershell)\\\\s*((?:Ansible|ansible_collections|\\\\.)\\\\..+)\\', line)\\n\\n        if not match:\\n            continue\\n\\n        import_name = resolve_csharp_ps_util(match.group(1), path)\\n\\n        if import_name in module_utils:\\n            imports.add(import_name)\\n        elif data_context().content.is_ansible or \\\\\\n                import_name.startswith(\\'ansible_collections.%s\\' % data_context().content.prefix):\\n            display.warning(\\'%s:%d Invalid module_utils import: %s\\' % (path, line_number, import_name))\\n\\n    return imports\\n',\n  'problems': []},\n ...]"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "from rules.rule_processor import run_rules_on_dataset\n",
    "\n",
    "processed_data = run_rules_on_dataset(data)\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.data = processed_data\n",
    "data_handler.dump_to_file(\"with_problems.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from input.data_read_write import DataReaderAndWriter\n",
    "data_handler = DataReaderAndWriter()\n",
    "data_handler.parse_from_pickle_file(\"with_problems.pkl\")\n",
    "processed_data = data_handler.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('raw_data/ansible/ansible/devel/ansible-devel/lib/ansible/utils/collection_loader/_collection_finder.py',\n  17),\n ('raw_data/django/django/master/django-master/django/db/models/fields/__init__.py',\n  16),\n ('raw_data/django/django/master/django-master/django/forms/fields.py', 13),\n ('raw_data/scikit-learn/scikit-learn/master/scikit-learn-master/doc/tutorial/machine_learning_map/pyparsing.py',\n  13),\n ('raw_data/django/django/master/django-master/django/db/backends/sqlite3/base.py',\n  12),\n ('raw_data/pytorch/pytorch/master/pytorch-master/torch/onnx/utils.py', 9),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/support/integration/plugins/module_utils/vmware.py',\n  8),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/support/integration/plugins/module_utils/docker/common.py',\n  8),\n ('raw_data/pytorch/pytorch/master/pytorch-master/torch/utils/collect_env.py',\n  8),\n ('raw_data/django/django/master/django-master/django/db/models/fields/related.py',\n  8),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/support/integration/plugins/module_utils/cloudstack.py',\n  7),\n ('raw_data/pytorch/pytorch/master/pytorch-master/torch/_jit_internal.py', 7),\n ('raw_data/django/django/master/django-master/django/contrib/admin/options.py',\n  7),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/support/integration/plugins/module_utils/crypto.py',\n  6),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/support/integration/plugins/module_utils/docker/swarm.py',\n  6),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/lib/ansible_test/_data/sanity/import/importer.py',\n  6),\n ('raw_data/pytorch/pytorch/master/pytorch-master/tools/autograd/gen_variable_type.py',\n  6),\n ('raw_data/pytorch/pytorch/master/pytorch-master/caffe2/python/data_parallel_model_test.py',\n  6),\n ('raw_data/django/django/master/django-master/django/db/migrations/questioner.py',\n  6),\n ('raw_data/django/django/master/django-master/django/db/backends/base/operations.py',\n  6),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/lib/ansible_test/_internal/classification.py',\n  5),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/lib/ansible_test/_internal/executor.py',\n  5),\n ('raw_data/pytorch/pytorch/master/pytorch-master/caffe2/python/core.py', 5),\n ('raw_data/pytorch/pytorch/master/pytorch-master/torch/jit/annotations.py',\n  5),\n ('raw_data/django/django/master/django-master/django/contrib/gis/gdal/field.py',\n  5),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/network/common/utils.py',\n  4),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/support/integration/plugins/module_utils/network/common/utils.py',\n  4),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/support/integration/plugins/modules/s3_bucket.py',\n  4),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/support/integration/plugins/modules/vmware_guest.py',\n  4),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/support/integration/plugins/modules/ec2_eni.py',\n  4),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/support/integration/plugins/modules/ec2_group.py',\n  4),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/support/integration/plugins/modules/openssl_certificate_info.py',\n  4),\n ('raw_data/ansible/ansible/devel/ansible-devel/lib/ansible/parsing/vault/__init__.py',\n  4),\n ('raw_data/ansible/ansible/devel/ansible-devel/lib/ansible/modules/user.py',\n  4),\n ('raw_data/ansible/ansible/devel/ansible-devel/lib/ansible/modules/git.py',\n  4),\n ('raw_data/pallets/flask/master/flask-master/src/flask/sessions.py', 4),\n ('raw_data/pytorch/pytorch/master/pytorch-master/torch/autograd/gradcheck.py',\n  4),\n ('raw_data/pytorch/pytorch/master/pytorch-master/torch/jit/_state.py', 4),\n ('raw_data/django/django/master/django-master/django/middleware/csrf.py', 4),\n ('raw_data/django/django/master/django-master/django/urls/resolvers.py', 4),\n ('raw_data/django/django/master/django-master/django/db/backends/base/schema.py',\n  4),\n ('raw_data/scikit-learn/scikit-learn/master/scikit-learn-master/sklearn/utils/__init__.py',\n  4),\n ('raw_data/keras-team/keras/master/keras-master/keras/utils/conv_utils.py',\n  3),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/support/network-integration/collections/ansible_collections/ansible/netcommon/plugins/module_utils/compat/ipaddress.py',\n  3),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/support/integration/plugins/module_utils/compat/ipaddress.py',\n  3),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/support/integration/plugins/modules/cs_role_permission.py',\n  3),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/lib/ansible_test/_internal/docker_util.py',\n  3),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/lib/ansible_test/_internal/core_ci.py',\n  3),\n ('raw_data/ansible/ansible/devel/ansible-devel/lib/ansible/plugins/loader.py',\n  3),\n ('raw_data/ansible/ansible/devel/ansible-devel/lib/ansible/plugins/action/copy.py',\n  3),\n ('raw_data/ansible/ansible/devel/ansible-devel/lib/ansible/utils/encrypt.py',\n  3),\n ('raw_data/ansible/ansible/devel/ansible-devel/lib/ansible/modules/service_facts.py',\n  3),\n ('raw_data/pytorch/pytorch/master/pytorch-master/test/test_jit.py', 3),\n ('raw_data/pytorch/pytorch/master/pytorch-master/torch/serialization.py', 3),\n ('raw_data/pytorch/pytorch/master/pytorch-master/torch/onnx/symbolic_helper.py',\n  3),\n ('raw_data/pytorch/pytorch/master/pytorch-master/torch/jit/_recursive.py', 3),\n ('raw_data/django/django/master/django-master/tests/middleware_exceptions/middleware.py',\n  3),\n ('raw_data/django/django/master/django-master/tests/cache/tests.py', 3),\n ('raw_data/django/django/master/django-master/tests/multiple_database/routers.py',\n  3),\n ('raw_data/django/django/master/django-master/tests/gis_tests/inspectapp/tests.py',\n  3),\n ('raw_data/django/django/master/django-master/django/middleware/cache.py', 3),\n ('raw_data/django/django/master/django-master/django/utils/translation/trans_null.py',\n  3),\n ('raw_data/django/django/master/django-master/django/contrib/messages/storage/cookie.py',\n  3),\n ('raw_data/django/django/master/django-master/django/contrib/auth/backends.py',\n  3),\n ('raw_data/django/django/master/django-master/django/contrib/gis/gdal/raster/source.py',\n  3),\n ('raw_data/django/django/master/django-master/django/db/backends/utils.py',\n  3),\n ('raw_data/django/django/master/django-master/django/db/backends/postgresql/operations.py',\n  3),\n ('raw_data/django/django/master/django-master/django/db/backends/oracle/operations.py',\n  3),\n ('raw_data/django/django/master/django-master/django/db/models/query_utils.py',\n  3),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/sanity/code-smell/update-bundled.py',\n  2),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/units/playbook/test_base.py',\n  2),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/units/plugins/strategy/test_strategy.py',\n  2),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/support/network-integration/collections/ansible_collections/vyos/vyos/plugins/module_utils/network/vyos/utils/utils.py',\n  2),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/support/integration/plugins/modules/ec2_vpc_net.py',\n  2),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/support/integration/plugins/modules/ec2_instance.py',\n  2),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/lib/ansible_test/_internal/ci/shippable.py',\n  2),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/lib/ansible_test/_internal/sanity/__init__.py',\n  2),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/lib/ansible_test/_internal/cloud/__init__.py',\n  2),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/lib/ansible_test/_internal/coverage/__init__.py',\n  2),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/lib/ansible_test/_data/collection_detail.py',\n  2),\n ('raw_data/ansible/ansible/devel/ansible-devel/test/lib/ansible_test/_data/sanity/code-smell/action-plugin-docs.py',\n  2),\n ('raw_data/ansible/ansible/devel/ansible-devel/lib/ansible/playbook/task.py',\n  2),\n ('raw_data/ansible/ansible/devel/ansible-devel/lib/ansible/playbook/block.py',\n  2),\n ('raw_data/ansible/ansible/devel/ansible-devel/lib/ansible/module_utils/connection.py',\n  2),\n ('raw_data/ansible/ansible/devel/ansible-devel/lib/ansible/module_utils/basic.py',\n  2),\n ('raw_data/ansible/ansible/devel/ansible-devel/lib/ansible/module_utils/six/__init__.py',\n  2),\n ('raw_data/ansible/ansible/devel/ansible-devel/lib/ansible/module_utils/facts/other/ohai.py',\n  2),\n ('raw_data/ansible/ansible/devel/ansible-devel/lib/ansible/module_utils/facts/other/facter.py',\n  2),\n ('raw_data/ansible/ansible/devel/ansible-devel/lib/ansible/modules/cron.py',\n  2),\n ('raw_data/ansible/ansible/devel/ansible-devel/lib/ansible/modules/dnf.py',\n  2),\n ('raw_data/pallets/flask/master/flask-master/tests/test_reqctx.py', 2),\n ('raw_data/pytorch/pytorch/master/pytorch-master/test/test_nn.py', 2),\n ('raw_data/pytorch/pytorch/master/pytorch-master/test/test_autograd.py', 2),\n ('raw_data/pytorch/pytorch/master/pytorch-master/caffe2/python/rnn_cell.py',\n  2),\n ('raw_data/pytorch/pytorch/master/pytorch-master/caffe2/python/regularizer.py',\n  2),\n ('raw_data/pytorch/pytorch/master/pytorch-master/caffe2/python/schema.py', 2),\n ('raw_data/pytorch/pytorch/master/pytorch-master/caffe2/python/predictor/predictor_py_utils.py',\n  2),\n ('raw_data/pytorch/pytorch/master/pytorch-master/caffe2/contrib/playground/ModuleRegister.py',\n  2),\n ('raw_data/pytorch/pytorch/master/pytorch-master/torch/_utils.py', 2),\n ('raw_data/pytorch/pytorch/master/pytorch-master/torch/nn/utils/rnn.py', 2)]"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c = Counter()         \n",
    "for d in processed_data:\n",
    "    c[d[\"file_path\"]] += len(d[\"problems\"])\n",
    "c.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List file with number of problems"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitownclassifiervenv09c541dae239465b81df0e9aaa9c8025",
   "display_name": "Python 3.8.5 64-bit ('own_classifier': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}