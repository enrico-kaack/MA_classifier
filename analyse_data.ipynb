{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bitownclassifiervenv97636dc04982443f83ed0d68878d1cc4",
   "display_name": "Python 3.7.3 64-bit ('own_classifier': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Loading postgres module without psycopg2 installed. Will crash at runtime if postgres functionality is used.\nLoading S3 module without the python package boto3. Will crash at runtime if S3 functionality is used.\nWelcome to d6tflow!\n"
    }
   ],
   "source": [
    "from tasks.preprocessing import TaskRuleProcessor, ProblemType, TaskSourceFileToDataStructure\n",
    "from input.input_data_analysis import analyse_parsed_data\n",
    "import d6tflow\n",
    "d6tflow.settings.log_level = 'WARNING' # 'DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Lines of Code: 1372290\nTotal Files: 6623\nLOCs per file 207.20066435150235\nLOCs containing probem RETURN_NULL: 0.00047876177775834554\nProblems per file for RETURN_NULL: 0.09919975841763551\nLOCs containing probem CONDITION_COMPARISON: 0.03098251827237683\nProblems per file for CONDITION_COMPARISON: 6.41959836931904\n"
    }
   ],
   "source": [
    "d6tflow.run(TaskRuleProcessor(input_src_path=\"raw_data\"))\n",
    "problems = TaskRuleProcessor(input_src_path=\"raw_data\").outputLoad()\n",
    "analyse_parsed_data(problems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract a random validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "14811"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "all_files = []\n",
    "for dir_path, dir_names, file_names in os.walk(\"second_large_dataset\"):\n",
    "            for f in file_names:\n",
    "                _, file_extension = os.path.splitext(f)\n",
    "                if file_extension == \".py\":\n",
    "                    file_path = os.path.join(dir_path, f)\n",
    "                    all_files.append(file_path)\n",
    "len(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(18513, 3702)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "validation_ratio = 0.2\n",
    "\n",
    "sample = random.sample(all_files, k=int(validation_ratio*len(all_files)))\n",
    "len(all_files), len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "for f in sample:\n",
    "    target_path = os.path.join(\"validation/extracted\", f)\n",
    "    os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
    "    shutil.move(f, target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input/validation_extracted.txt\", \"w\") as outfile:\n",
    "    outfile.writelines(\"\\n\".join(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run analysis on remaining dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "###Running TaskSourceFileToDataStructure\n  0%|          | 0/14811 [00:00<?, ?it/s]###Running TaskRuleProcessor\n 21%|██        | 3102/14811 [03:03<21:36,  9.03it/s]WARNING:root:Syntax error on file:second_large_dataset/ansible/ansible/devel/ansible-devel/test/support/windows-integration/collections/ansible_collections/ansible/windows/plugins/action/win_copy.py. Ignoring file\nWARNING:root:Syntax error on file:second_large_dataset/ansible/ansible/devel/ansible-devel/test/support/windows-integration/collections/ansible_collections/ansible/windows/plugins/action/win_copy.py. Ignoring file\nWARNING:root:Syntax error on file:second_large_dataset/ansible/ansible/devel/ansible-devel/test/support/windows-integration/collections/ansible_collections/ansible/windows/plugins/modules/win_stat.py. Ignoring file\nWARNING:root:Syntax error on file:second_large_dataset/ansible/ansible/devel/ansible-devel/test/support/windows-integration/collections/ansible_collections/ansible/windows/plugins/modules/win_stat.py. Ignoring file\nWARNING:root:Syntax error on file:second_large_dataset/ansible/ansible/devel/ansible-devel/test/support/windows-integration/collections/ansible_collections/ansible/windows/plugins/modules/win_file.py. Ignoring file\nWARNING:root:Syntax error on file:second_large_dataset/ansible/ansible/devel/ansible-devel/test/support/windows-integration/collections/ansible_collections/ansible/windows/plugins/modules/win_file.py. Ignoring file\nWARNING:root:Syntax error on file:second_large_dataset/ansible/ansible/devel/ansible-devel/test/support/windows-integration/collections/ansible_collections/ansible/windows/plugins/modules/win_ping.py. Ignoring file\nWARNING:root:Syntax error on file:second_large_dataset/ansible/ansible/devel/ansible-devel/test/support/windows-integration/collections/ansible_collections/ansible/windows/plugins/modules/win_ping.py. Ignoring file\nWARNING:root:Syntax error on file:second_large_dataset/ansible/ansible/devel/ansible-devel/test/support/windows-integration/collections/ansible_collections/ansible/windows/plugins/modules/win_copy.py. Ignoring file\nWARNING:root:Syntax error on file:second_large_dataset/ansible/ansible/devel/ansible-devel/test/support/windows-integration/collections/ansible_collections/ansible/windows/plugins/modules/win_copy.py. Ignoring file\n 23%|██▎       | 3422/14811 [03:18<33:54,  5.60it/s]WARNING:root:Syntax error on file:second_large_dataset/ansible/ansible/devel/ansible-devel/lib/ansible/module_utils/ansible_release.py. Ignoring file\nWARNING:root:Syntax error on file:second_large_dataset/ansible/ansible/devel/ansible-devel/lib/ansible/module_utils/ansible_release.py. Ignoring file\n 60%|██████    | 8932/14811 [06:32<07:12, 13.60it/s]WARNING:root:Syntax error on file:second_large_dataset/pytorch/pytorch/master/pytorch-master/tools/autograd/templates/annotated_fn_args.py. Ignoring file\nWARNING:root:Syntax error on file:second_large_dataset/pytorch/pytorch/master/pytorch-master/tools/autograd/templates/annotated_fn_args.py. Ignoring file\n 88%|████████▊ | 13027/14811 [10:18<02:38, 11.24it/s]WARNING:root:Syntax error on file:second_large_dataset/apache/airflow/master/airflow-master/backport_packages/airflow/version.py. Ignoring file\nWARNING:root:Syntax error on file:second_large_dataset/apache/airflow/master/airflow-master/backport_packages/airflow/version.py. Ignoring file\n100%|██████████| 14811/14811 [11:33<00:00, 21.35it/s]\nLines of Code: 2789853\nTotal Files: 14811\nLOCs per file 188.36358112213895\nLOCs containing probem RETURN_NULL: 0.0007530862737212319\nProblems per file for RETURN_NULL: 0.1418540274120586\nLOCs containing probem CONDITION_COMPARISON: 0.0235786616714214\nProblems per file for CONDITION_COMPARISON: 4.4413611504962525\n"
    }
   ],
   "source": [
    "TaskSourceFileToDataStructure(input_src_path=\"second_large_dataset\").invalidate(confirm=False)\n",
    "d6tflow.run(TaskRuleProcessor(input_src_path=\"second_large_dataset\"))\n",
    "problems = TaskRuleProcessor(input_src_path=\"second_large_dataset\").outputLoad()\n",
    "analyse_parsed_data(problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Lines of Code: 658966\nTotal Files: 3702\nLOCs per file 178.0027012425716\nLOCs containing probem RETURN_NULL: 0.0007617995465623416\nProblems per file for RETURN_NULL: 0.13560237709346298\nLOCs containing probem CONDITION_COMPARISON: 0.02508171893542307\nProblems per file for CONDITION_COMPARISON: 4.464613722312263\n"
    }
   ],
   "source": [
    "d6tflow.run(TaskRuleProcessor(input_src_path=\"validation\"))\n",
    "problems = TaskRuleProcessor(input_src_path=\"validation\").outputLoad()\n",
    "analyse_parsed_data(problems)"
   ]
  }
 ]
}